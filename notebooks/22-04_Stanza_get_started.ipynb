{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur la page web (https://stanfordnlp.github.io/stanfordnlp/), ils disent de plutôt installer Stanza \n",
    "- site web : https://stanfordnlp.github.io/stanza/\n",
    "- github : https://stanfordnlp.github.io/stanza/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install stanza "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "import yaml\n",
    "with open(\"config.yml\", \"r\") as ymlfile:\n",
    "    cfg = yaml.safe_load(ymlfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stanza.download('fr') # download french model\n",
    "# Si ça ne marche pas (à cause du proxy ou autre):\n",
    "# 1 - Télécharger le fichier ci-dessous et le mettre dans /root/stanza_resources/ : \n",
    "# https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.2.0.json\n",
    "# 2 - Télécharger le dossier zippé ci-dessous et le mettre dans /root/stanza_resources/fr/: \n",
    "# http://nlp.stanford.edu/software/stanza/1.2.0/fr/default.zip\n",
    "# 3 - Dézipper l'archive avec unzip ou jar xvf\n",
    "# 4 -  Si l'étape 3 ne marche pas entièrement :\n",
    "## 1 - Vérifier dans  /root/stanza_resources/fr/ qu'au moins les dossiers backward_charlm et forward_charlm ont été générés\n",
    "## 2 - Supprimer l'archive, et retélécharger le default.zip pour le redézipper dans http://nlp.stanford.edu/software/stanza/1.2.0/fr/\n",
    "\n",
    "\n",
    "# Attention ! : ls /root/stanza_resources/fr/ DOIT RENDRE :\n",
    "# backward_charlm  default.zip  depparse  forward_charlm  lemma  mwt  ner  pos  pretrain  tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-07 12:19:52 INFO: Loading these models for language: fr (French):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | gsd     |\n",
      "| mwt       | gsd     |\n",
      "| pos       | gsd     |\n",
      "| lemma     | gsd     |\n",
      "| depparse  | gsd     |\n",
      "| ner       | wikiner |\n",
      "=======================\n",
      "\n",
      "2022-04-07 12:19:52 INFO: Use device: gpu\n",
      "2022-04-07 12:19:52 INFO: Loading: tokenize\n",
      "2022-04-07 12:19:54 INFO: Loading: mwt\n",
      "2022-04-07 12:19:54 INFO: Loading: pos\n",
      "2022-04-07 12:19:54 INFO: Loading: lemma\n",
      "2022-04-07 12:19:54 INFO: Loading: depparse\n",
      "2022-04-07 12:19:55 INFO: Loading: ner\n",
      "2022-04-07 12:19:56 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp_fr= stanza.Pipeline('fr') # initialize French neural pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook est vraiment un brouillon pour voir comment stanza annote. À a la toute fin, il y a une visualisation BRAT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Barack', 4, 'nsubj')\n",
      "('Obama', 1, 'flat:name')\n",
      "('est', 4, 'aux:tense')\n",
      "('né', 0, 'root')\n",
      "('à', 6, 'case')\n",
      "('Hawaii', 4, 'obl:arg')\n",
      "('.', 4, 'punct')\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp_fr(\"Barack Obama est né à Hawaii.\")\n",
    "doc = nlp_fr(\"Barack Obama est né à Hawaii. Il a vécu tout sa vie aux US.\") # run annotation over a sentence\n",
    "doc.sentences[0].print_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = nlp_fr('Radioépithélite de grade 1. Asthésnie de grade 3. La patiente présente une néphtopathie de grade 1 . La patiente présente aussi une néphtopathie de grade 1. La patiente présente aussi une néphtopathie de grade 1 et elle a de la toux iatrogène. Elle voulait acheter et manger une pomme. Nous avons atteint la fin du sentier. Syndrome mains pieds de grade 2.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Syndrome', 0, 'root')\n",
      "('mains', 1, 'nmod')\n",
      "('pieds', 1, 'nmod')\n",
      "('de', 5, 'case')\n",
      "('grade', 3, 'nmod')\n",
      "('2', 5, 'nmod')\n",
      "('.', 1, 'punct')\n"
     ]
    }
   ],
   "source": [
    "doc3.sentences[-1].print_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Radioépithélite\n",
      "de\n",
      "grade\n",
      "1\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "sent = doc3.sentences[0] \n",
    "for word in sent.words :\n",
    "    print(word.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(sent.words[0].id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the word {'id': 1, 'text': 'Nous', 'lemma': 'il', 'upos': 'PRON', 'feats': 'Number=Plur|Person=1|PronType=Prs', 'head': 3, 'deprel': 'nsubj', 'misc': 'start_char=286|end_char=290'}\n",
      "word.parent.id (1,)\n",
      "word.parent.head Nous\n",
      "its parent [{'id': 1, 'text': 'Nous', 'lemma': 'il', 'upos': 'PRON', 'feats': 'Number=Plur|Person=1|PronType=Prs', 'head': 3, 'deprel': 'nsubj', 'misc': 'start_char=286|end_char=290', 'ner': 'O'}]\n",
      "the word {'id': 2, 'text': 'avons', 'lemma': 'avoir', 'upos': 'AUX', 'feats': 'Mood=Ind|Number=Plur|Person=1|Tense=Pres|VerbForm=Fin', 'head': 3, 'deprel': 'aux:tense', 'misc': 'start_char=291|end_char=296'}\n",
      "word.parent.id (2,)\n",
      "word.parent.head avons\n",
      "its parent [{'id': 2, 'text': 'avons', 'lemma': 'avoir', 'upos': 'AUX', 'feats': 'Mood=Ind|Number=Plur|Person=1|Tense=Pres|VerbForm=Fin', 'head': 3, 'deprel': 'aux:tense', 'misc': 'start_char=291|end_char=296', 'ner': 'O'}]\n",
      "the word {'id': 3, 'text': 'atteint', 'lemma': 'atteindre', 'upos': 'VERB', 'feats': 'Gender=Masc|Number=Sing|Tense=Past|VerbForm=Part', 'head': 0, 'deprel': 'root', 'misc': 'start_char=297|end_char=304'}\n",
      "word.parent.id (3,)\n",
      "word.parent.head atteint\n",
      "its parent [{'id': 3, 'text': 'atteint', 'lemma': 'atteindre', 'upos': 'VERB', 'feats': 'Gender=Masc|Number=Sing|Tense=Past|VerbForm=Part', 'head': 0, 'deprel': 'root', 'misc': 'start_char=297|end_char=304', 'ner': 'O'}]\n",
      "the word {'id': 4, 'text': 'la', 'lemma': 'le', 'upos': 'DET', 'feats': 'Definite=Def|Gender=Fem|Number=Sing|PronType=Art', 'head': 5, 'deprel': 'det', 'misc': 'start_char=305|end_char=307'}\n",
      "word.parent.id (4,)\n",
      "word.parent.head la\n",
      "its parent [{'id': 4, 'text': 'la', 'lemma': 'le', 'upos': 'DET', 'feats': 'Definite=Def|Gender=Fem|Number=Sing|PronType=Art', 'head': 5, 'deprel': 'det', 'misc': 'start_char=305|end_char=307', 'ner': 'O'}]\n",
      "the word {'id': 5, 'text': 'fin', 'lemma': 'fin', 'upos': 'NOUN', 'feats': 'Gender=Fem|Number=Sing', 'head': 3, 'deprel': 'obj', 'misc': 'start_char=308|end_char=311'}\n",
      "word.parent.id (5,)\n",
      "word.parent.head fin\n",
      "its parent [{'id': 5, 'text': 'fin', 'lemma': 'fin', 'upos': 'NOUN', 'feats': 'Gender=Fem|Number=Sing', 'head': 3, 'deprel': 'obj', 'misc': 'start_char=308|end_char=311', 'ner': 'O'}]\n",
      "the word {'id': 6, 'text': 'de', 'lemma': 'de', 'upos': 'ADP', 'head': 8, 'deprel': 'case'}\n",
      "word.parent.id (6, 7)\n",
      "word.parent.head du\n",
      "its parent [{'id': (6, 7), 'text': 'du', 'ner': 'O', 'misc': 'start_char=312|end_char=314'}, {'id': 6, 'text': 'de', 'lemma': 'de', 'upos': 'ADP', 'head': 8, 'deprel': 'case'}, {'id': 7, 'text': 'le', 'lemma': 'le', 'upos': 'DET', 'feats': 'Definite=Def|Gender=Masc|Number=Sing|PronType=Art', 'head': 8, 'deprel': 'det'}]\n",
      "the word {'id': 7, 'text': 'le', 'lemma': 'le', 'upos': 'DET', 'feats': 'Definite=Def|Gender=Masc|Number=Sing|PronType=Art', 'head': 8, 'deprel': 'det'}\n",
      "word.parent.id (6, 7)\n",
      "word.parent.head du\n",
      "its parent [{'id': (6, 7), 'text': 'du', 'ner': 'O', 'misc': 'start_char=312|end_char=314'}, {'id': 6, 'text': 'de', 'lemma': 'de', 'upos': 'ADP', 'head': 8, 'deprel': 'case'}, {'id': 7, 'text': 'le', 'lemma': 'le', 'upos': 'DET', 'feats': 'Definite=Def|Gender=Masc|Number=Sing|PronType=Art', 'head': 8, 'deprel': 'det'}]\n",
      "the word {'id': 8, 'text': 'sentier', 'lemma': 'sentier', 'upos': 'NOUN', 'feats': 'Gender=Masc|Number=Sing', 'head': 5, 'deprel': 'nmod', 'misc': 'start_char=315|end_char=322'}\n",
      "word.parent.id (8,)\n",
      "word.parent.head sentier\n",
      "its parent [{'id': 8, 'text': 'sentier', 'lemma': 'sentier', 'upos': 'NOUN', 'feats': 'Gender=Masc|Number=Sing', 'head': 5, 'deprel': 'nmod', 'misc': 'start_char=315|end_char=322', 'ner': 'O'}]\n",
      "the word {'id': 9, 'text': '.', 'lemma': '.', 'upos': 'PUNCT', 'head': 3, 'deprel': 'punct', 'misc': 'start_char=322|end_char=323'}\n",
      "word.parent.id (9,)\n",
      "word.parent.head .\n",
      "its parent [{'id': 9, 'text': '.', 'lemma': '.', 'upos': 'PUNCT', 'head': 3, 'deprel': 'punct', 'misc': 'start_char=322|end_char=323', 'ner': 'O'}]\n"
     ]
    }
   ],
   "source": [
    "sent = doc3.sentences[-2] \n",
    "for word in sent.words :\n",
    "    print(\"the word\", word.to_dict())\n",
    "    print(\"word.parent.id\",word.parent.id)\n",
    "    print(\"word.parent.head\",word.parent.text)\n",
    "    print(\"its parent\", word.parent.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the word Radioépithélite\n",
      "to_dict {'id': 1, 'text': 'Radioépithélite', 'lemma': 'Radioépithélite', 'upos': 'PROPN', 'head': 0, 'deprel': 'root', 'misc': 'start_char=0|end_char=15'}\n",
      "the word de\n",
      "to_dict {'id': 2, 'text': 'de', 'lemma': 'de', 'upos': 'ADP', 'head': 3, 'deprel': 'case', 'misc': 'start_char=16|end_char=18'}\n",
      "the word grade\n",
      "to_dict {'id': 3, 'text': 'grade', 'lemma': 'grade', 'upos': 'NOUN', 'feats': 'Gender=Masc|Number=Sing', 'head': 1, 'deprel': 'nmod', 'misc': 'start_char=19|end_char=24'}\n",
      "the word 1\n",
      "to_dict {'id': 4, 'text': '1', 'lemma': '1', 'upos': 'NUM', 'feats': 'Number=Plur', 'head': 3, 'deprel': 'nmod', 'misc': 'start_char=25|end_char=26'}\n",
      "the word .\n",
      "to_dict {'id': 5, 'text': '.', 'lemma': '.', 'upos': 'PUNCT', 'head': 1, 'deprel': 'punct', 'misc': 'start_char=26|end_char=27'}\n"
     ]
    }
   ],
   "source": [
    "sent = doc3.sentences[0] \n",
    "for word in sent.words :\n",
    "    print(\"the word\", word.text)\n",
    "    print(\"to_dict\", word.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'a', 2: 'b'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_1 = {1:\"a\"}\n",
    "dict_2 = {2:\"b\"}\n",
    "dict_ent = {**dict_1, **dict_2}\n",
    "dict_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent_to_dict <bound method Sentence.to_dict of [\n",
      "  {\n",
      "    \"id\": 1,\n",
      "    \"text\": \"Radioépithélite\",\n",
      "    \"lemma\": \"Radioépithélite\",\n",
      "    \"upos\": \"PROPN\",\n",
      "    \"head\": 0,\n",
      "    \"deprel\": \"root\",\n",
      "    \"misc\": \"start_char=0|end_char=15\",\n",
      "    \"ner\": \"O\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": 2,\n",
      "    \"text\": \"de\",\n",
      "    \"lemma\": \"de\",\n",
      "    \"upos\": \"ADP\",\n",
      "    \"head\": 3,\n",
      "    \"deprel\": \"case\",\n",
      "    \"misc\": \"start_char=16|end_char=18\",\n",
      "    \"ner\": \"O\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": 3,\n",
      "    \"text\": \"grade\",\n",
      "    \"lemma\": \"grade\",\n",
      "    \"upos\": \"NOUN\",\n",
      "    \"feats\": \"Gender=Masc|Number=Sing\",\n",
      "    \"head\": 1,\n",
      "    \"deprel\": \"nmod\",\n",
      "    \"misc\": \"start_char=19|end_char=24\",\n",
      "    \"ner\": \"O\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": 4,\n",
      "    \"text\": \"1\",\n",
      "    \"lemma\": \"1\",\n",
      "    \"upos\": \"NUM\",\n",
      "    \"feats\": \"Number=Plur\",\n",
      "    \"head\": 3,\n",
      "    \"deprel\": \"nmod\",\n",
      "    \"misc\": \"start_char=25|end_char=26\",\n",
      "    \"ner\": \"O\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": 5,\n",
      "    \"text\": \".\",\n",
      "    \"lemma\": \".\",\n",
      "    \"upos\": \"PUNCT\",\n",
      "    \"head\": 1,\n",
      "    \"deprel\": \"punct\",\n",
      "    \"misc\": \"start_char=26|end_char=27\",\n",
      "    \"ner\": \"O\"\n",
      "  }\n",
      "]>\n"
     ]
    }
   ],
   "source": [
    "sent = doc3.sentences[0] \n",
    "print(\"sent_to_dict\", sent.to_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parent(word_id, sentence):\n",
    "    \n",
    "    return(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_count=0\n",
    "for sentence in doc.sentences:\n",
    "    sent_count += 1\n",
    "    dep_counter = 0\n",
    "    print(\"\\n\\n\\n sent_count\", sent_count)\n",
    "    print(\"type(sentence.dependencies)\", type(sentence.dependencies))\n",
    "    for dep in sentence.dependencies :\n",
    "        dep_counter += 1\n",
    "        print(\"\\n\\n dep_counter\", dep_counter)\n",
    "        print(\"dep between : \")\n",
    "        for dico in dep :\n",
    "            if type(dico) == str :\n",
    "                print(\"str\")\n",
    "            else :\n",
    "                print(\"word\", dico.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Radioépithélite Radioépithélite PROPN\n",
      "de de ADP\n",
      "grade grade NOUN\n",
      "1 1 NUM\n",
      ". . PUNCT\n",
      "Asthésnie Asthésnie PROPN\n",
      "de de ADP\n",
      "grade grade NOUN\n",
      "3 3 NUM\n",
      ". . PUNCT\n",
      "La le DET\n",
      "patiente patient NOUN\n",
      "présente présenter VERB\n",
      "une un DET\n",
      "néphtopathie néphtopathie NOUN\n",
      "de de ADP\n",
      "grade grade NOUN\n",
      "1 1 NUM\n",
      ". . PUNCT\n",
      "La le DET\n",
      "patiente patient NOUN\n",
      "présente présenter VERB\n",
      "aussi aussi ADV\n",
      "une un DET\n",
      "néphtopathie néphtopathie NOUN\n",
      "de de ADP\n",
      "grade grade NOUN\n",
      "1 1 NUM\n",
      ". . PUNCT\n",
      "La le DET\n",
      "patiente patient NOUN\n",
      "présente présenter VERB\n",
      "aussi aussi ADV\n",
      "une un DET\n",
      "néphtopathie néphtopathie NOUN\n",
      "de de ADP\n",
      "grade grade NOUN\n",
      "1 1 NUM\n",
      "et et CCONJ\n",
      "elle il PRON\n",
      "a avoir VERB\n",
      "de de ADP\n",
      "la le DET\n",
      "toux toux NOUN\n",
      "iatrogène iatrogène ADJ\n",
      ". . PUNCT\n",
      "Elle il PRON\n",
      "voulait vouloir VERB\n",
      "acheter acheter VERB\n",
      "et et CCONJ\n",
      "manger manger VERB\n",
      "une un DET\n",
      "pomme pomme NOUN\n",
      ". . PUNCT\n",
      "Nous il PRON\n",
      "avons avoir AUX\n",
      "atteint atteindre VERB\n",
      "la le DET\n",
      "fin fin NOUN\n",
      "de de ADP\n",
      "le le DET\n",
      "sentier sentier NOUN\n",
      ". . PUNCT\n",
      "Syndrome syndrome NOUN\n",
      "mains main NOUN\n",
      "pieds pied NOUN\n",
      "de de ADP\n",
      "grade grade NOUN\n",
      "2 2 NUM\n",
      ". . PUNCT\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc3.sentences:\n",
    "    for word in sentence.words:\n",
    "        print(word.text, word.lemma, word.pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Il', 3, 'nsubj')\n",
      "('a', 3, 'aux:tense')\n",
      "('vécu', 0, 'root')\n",
      "('tout', 6, 'amod')\n",
      "('sa', 6, 'det')\n",
      "('vie', 3, 'obj')\n",
      "('à', 9, 'case')\n",
      "('les', 9, 'det')\n",
      "('US.', 3, 'obl:mod')\n"
     ]
    }
   ],
   "source": [
    "doc.sentences[1].print_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('La', 2, 'det')\n",
      "('patiente', 3, 'nsubj')\n",
      "('présente', 0, 'root')\n",
      "('une', 5, 'det')\n",
      "('néphtopathie', 3, 'obj')\n",
      "('de', 7, 'case')\n",
      "('grade', 5, 'nmod')\n",
      "('1', 7, 'nmod')\n",
      "('.', 3, 'punct')\n"
     ]
    }
   ],
   "source": [
    "doc3.sentences[2].print_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Radioépithélite', 0, 'root')\n",
      "('de', 3, 'case')\n",
      "('grade', 1, 'nmod')\n",
      "('1', 3, 'nmod')\n",
      "('.', 1, 'punct')\n"
     ]
    }
   ],
   "source": [
    "doc3.sentences[0].print_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Syndrome', 0, 'root')\n",
      "('mains', 1, 'nmod')\n",
      "('pieds', 1, 'nmod')\n",
      "('de', 5, 'case')\n",
      "('grade', 3, 'nmod')\n",
      "('2', 5, 'nmod')\n",
      "('.', 1, 'punct')\n"
     ]
    }
   ],
   "source": [
    "doc3.sentences[-1].print_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\tword: Radioépithélite\tmisc_0: start_char=0|end_char=15\thead id: 0\thead: root\tdeprel: root\n",
      "id: 2\tword: de\tmisc_0: start_char=16|end_char=18\thead id: 3\thead: grade\tdeprel: case\n",
      "id: 3\tword: grade\tmisc_0: start_char=19|end_char=24\thead id: 1\thead: Radioépithélite\tdeprel: nmod\n",
      "id: 4\tword: 1\tmisc_0: start_char=25|end_char=26\thead id: 3\thead: grade\tdeprel: nmod\n",
      "id: 5\tword: .\tmisc_0: start_char=26|end_char=27\thead id: 1\thead: Radioépithélite\tdeprel: punct\n",
      "id: 1\tword: Asthésnie\tmisc_0: start_char=28|end_char=37\thead id: 0\thead: root\tdeprel: root\n",
      "id: 2\tword: de\tmisc_0: start_char=38|end_char=40\thead id: 3\thead: grade\tdeprel: case\n",
      "id: 3\tword: grade\tmisc_0: start_char=41|end_char=46\thead id: 1\thead: Asthésnie\tdeprel: nmod\n",
      "id: 4\tword: 3\tmisc_0: start_char=47|end_char=48\thead id: 3\thead: grade\tdeprel: nmod\n",
      "id: 5\tword: .\tmisc_0: start_char=48|end_char=49\thead id: 1\thead: Asthésnie\tdeprel: punct\n",
      "id: 1\tword: La\tmisc_0: start_char=50|end_char=52\thead id: 2\thead: patiente\tdeprel: det\n",
      "id: 2\tword: patiente\tmisc_0: start_char=53|end_char=61\thead id: 3\thead: présente\tdeprel: nsubj\n",
      "id: 3\tword: présente\tmisc_0: start_char=62|end_char=70\thead id: 0\thead: root\tdeprel: root\n",
      "id: 4\tword: une\tmisc_0: start_char=71|end_char=74\thead id: 5\thead: néphtopathie\tdeprel: det\n",
      "id: 5\tword: néphtopathie\tmisc_0: start_char=75|end_char=87\thead id: 3\thead: présente\tdeprel: obj\n",
      "id: 6\tword: de\tmisc_0: start_char=88|end_char=90\thead id: 7\thead: grade\tdeprel: case\n",
      "id: 7\tword: grade\tmisc_0: start_char=91|end_char=96\thead id: 5\thead: néphtopathie\tdeprel: nmod\n",
      "id: 8\tword: 1\tmisc_0: start_char=97|end_char=98\thead id: 7\thead: grade\tdeprel: nmod\n",
      "id: 9\tword: .\tmisc_0: start_char=99|end_char=100\thead id: 3\thead: présente\tdeprel: punct\n",
      "id: 1\tword: La\tmisc_0: start_char=101|end_char=103\thead id: 2\thead: patiente\tdeprel: det\n",
      "id: 2\tword: patiente\tmisc_0: start_char=104|end_char=112\thead id: 3\thead: présente\tdeprel: nsubj\n",
      "id: 3\tword: présente\tmisc_0: start_char=113|end_char=121\thead id: 0\thead: root\tdeprel: root\n",
      "id: 4\tword: aussi\tmisc_0: start_char=122|end_char=127\thead id: 3\thead: présente\tdeprel: advmod\n",
      "id: 5\tword: une\tmisc_0: start_char=128|end_char=131\thead id: 6\thead: néphtopathie\tdeprel: det\n",
      "id: 6\tword: néphtopathie\tmisc_0: start_char=132|end_char=144\thead id: 3\thead: présente\tdeprel: obj\n",
      "id: 7\tword: de\tmisc_0: start_char=145|end_char=147\thead id: 8\thead: grade\tdeprel: case\n",
      "id: 8\tword: grade\tmisc_0: start_char=148|end_char=153\thead id: 6\thead: néphtopathie\tdeprel: nmod\n",
      "id: 9\tword: 1\tmisc_0: start_char=154|end_char=155\thead id: 8\thead: grade\tdeprel: nmod\n",
      "id: 10\tword: .\tmisc_0: start_char=155|end_char=156\thead id: 3\thead: présente\tdeprel: punct\n",
      "id: 1\tword: La\tmisc_0: start_char=157|end_char=159\thead id: 2\thead: patiente\tdeprel: det\n",
      "id: 2\tword: patiente\tmisc_0: start_char=160|end_char=168\thead id: 3\thead: présente\tdeprel: nsubj\n",
      "id: 3\tword: présente\tmisc_0: start_char=169|end_char=177\thead id: 0\thead: root\tdeprel: root\n",
      "id: 4\tword: aussi\tmisc_0: start_char=178|end_char=183\thead id: 3\thead: présente\tdeprel: advmod\n",
      "id: 5\tword: une\tmisc_0: start_char=184|end_char=187\thead id: 6\thead: néphtopathie\tdeprel: det\n",
      "id: 6\tword: néphtopathie\tmisc_0: start_char=188|end_char=200\thead id: 3\thead: présente\tdeprel: obj\n",
      "id: 7\tword: de\tmisc_0: start_char=201|end_char=203\thead id: 8\thead: grade\tdeprel: case\n",
      "id: 8\tword: grade\tmisc_0: start_char=204|end_char=209\thead id: 6\thead: néphtopathie\tdeprel: nmod\n",
      "id: 9\tword: 1\tmisc_0: start_char=210|end_char=211\thead id: 8\thead: grade\tdeprel: nmod\n",
      "id: 10\tword: et\tmisc_0: start_char=212|end_char=214\thead id: 12\thead: a\tdeprel: cc\n",
      "id: 11\tword: elle\tmisc_0: start_char=215|end_char=219\thead id: 12\thead: a\tdeprel: nsubj\n",
      "id: 12\tword: a\tmisc_0: start_char=220|end_char=221\thead id: 3\thead: présente\tdeprel: conj\n",
      "id: 13\tword: de\tmisc_0: start_char=222|end_char=224\thead id: 15\thead: toux\tdeprel: det\n",
      "id: 14\tword: la\tmisc_0: start_char=225|end_char=227\thead id: 13\thead: de\tdeprel: fixed\n",
      "id: 15\tword: toux\tmisc_0: start_char=228|end_char=232\thead id: 12\thead: a\tdeprel: obj\n",
      "id: 16\tword: iatrogène\tmisc_0: start_char=233|end_char=242\thead id: 15\thead: toux\tdeprel: amod\n",
      "id: 17\tword: .\tmisc_0: start_char=242|end_char=243\thead id: 3\thead: présente\tdeprel: punct\n",
      "id: 1\tword: Elle\tmisc_0: start_char=244|end_char=248\thead id: 2\thead: voulait\tdeprel: nsubj\n",
      "id: 2\tword: voulait\tmisc_0: start_char=249|end_char=256\thead id: 0\thead: root\tdeprel: root\n",
      "id: 3\tword: acheter\tmisc_0: start_char=257|end_char=264\thead id: 2\thead: voulait\tdeprel: xcomp:obj\n",
      "id: 4\tword: et\tmisc_0: start_char=265|end_char=267\thead id: 5\thead: manger\tdeprel: cc\n",
      "id: 5\tword: manger\tmisc_0: start_char=268|end_char=274\thead id: 3\thead: acheter\tdeprel: conj\n",
      "id: 6\tword: une\tmisc_0: start_char=275|end_char=278\thead id: 7\thead: pomme\tdeprel: det\n",
      "id: 7\tword: pomme\tmisc_0: start_char=279|end_char=284\thead id: 3\thead: acheter\tdeprel: obj\n",
      "id: 8\tword: .\tmisc_0: start_char=284|end_char=285\thead id: 2\thead: voulait\tdeprel: punct\n",
      "id: 1\tword: Nous\tmisc_0: start_char=286|end_char=290\thead id: 3\thead: atteint\tdeprel: nsubj\n",
      "id: 2\tword: avons\tmisc_0: start_char=291|end_char=296\thead id: 3\thead: atteint\tdeprel: aux:tense\n",
      "id: 3\tword: atteint\tmisc_0: start_char=297|end_char=304\thead id: 0\thead: root\tdeprel: root\n",
      "id: 4\tword: la\tmisc_0: start_char=305|end_char=307\thead id: 5\thead: fin\tdeprel: det\n",
      "id: 5\tword: fin\tmisc_0: start_char=308|end_char=311\thead id: 3\thead: atteint\tdeprel: obj\n",
      "id: 6\tword: de\tmisc_0: None\thead id: 8\thead: sentier\tdeprel: case\n",
      "id: 7\tword: le\tmisc_0: None\thead id: 8\thead: sentier\tdeprel: det\n",
      "id: 8\tword: sentier\tmisc_0: start_char=315|end_char=322\thead id: 5\thead: fin\tdeprel: nmod\n",
      "id: 9\tword: .\tmisc_0: start_char=322|end_char=323\thead id: 3\thead: atteint\tdeprel: punct\n",
      "id: 1\tword: Syndrome\tmisc_0: start_char=324|end_char=332\thead id: 0\thead: root\tdeprel: root\n",
      "id: 2\tword: mains\tmisc_0: start_char=333|end_char=338\thead id: 1\thead: Syndrome\tdeprel: nmod\n",
      "id: 3\tword: pieds\tmisc_0: start_char=339|end_char=344\thead id: 1\thead: Syndrome\tdeprel: nmod\n",
      "id: 4\tword: de\tmisc_0: start_char=345|end_char=347\thead id: 5\thead: grade\tdeprel: case\n",
      "id: 5\tword: grade\tmisc_0: start_char=348|end_char=353\thead id: 3\thead: pieds\tdeprel: nmod\n",
      "id: 6\tword: 2\tmisc_0: start_char=354|end_char=355\thead id: 5\thead: grade\tdeprel: nmod\n",
      "id: 7\tword: .\tmisc_0: start_char=355|end_char=356\thead id: 1\thead: Syndrome\tdeprel: punct\n"
     ]
    }
   ],
   "source": [
    "print(*[f'id: {word.id}\\tword: {word.text}\\tmisc_0: {word.misc}\\thead id: {word.head}\\thead: {sent.words[word.head-1].text if word.head > 0 else \"root\"}\\tdeprel: {word.deprel}' for sent in doc3.sentences for word in sent.words], sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\tword: Radioépithélite\tmisc_0: start_char=0|end_char=15\thead id: 0\thead: root\tdeprel: root\n",
      "id: 2\tword: de\tmisc_0: start_char=16|end_char=18\thead id: 3\thead: grade\tdeprel: case\n",
      "id: 3\tword: grade\tmisc_0: start_char=19|end_char=24\thead id: 1\thead: Radioépithélite\tdeprel: nmod\n",
      "id: 4\tword: 1\tmisc_0: start_char=25|end_char=26\thead id: 3\thead: grade\tdeprel: nmod\n",
      "id: 5\tword: .\tmisc_0: start_char=26|end_char=27\thead id: 1\thead: Radioépithélite\tdeprel: punct\n",
      "id: 1\tword: Asthésnie\tmisc_0: start_char=28|end_char=37\thead id: 0\thead: root\tdeprel: root\n",
      "id: 2\tword: de\tmisc_0: start_char=38|end_char=40\thead id: 3\thead: grade\tdeprel: case\n",
      "id: 3\tword: grade\tmisc_0: start_char=41|end_char=46\thead id: 1\thead: Asthésnie\tdeprel: nmod\n",
      "id: 4\tword: 3\tmisc_0: start_char=47|end_char=48\thead id: 3\thead: grade\tdeprel: nmod\n",
      "id: 5\tword: .\tmisc_0: start_char=48|end_char=49\thead id: 1\thead: Asthésnie\tdeprel: punct\n",
      "id: 1\tword: La\tmisc_0: start_char=50|end_char=52\thead id: 2\thead: patiente\tdeprel: det\n",
      "id: 2\tword: patiente\tmisc_0: start_char=53|end_char=61\thead id: 3\thead: présente\tdeprel: nsubj\n",
      "id: 3\tword: présente\tmisc_0: start_char=62|end_char=70\thead id: 0\thead: root\tdeprel: root\n",
      "id: 4\tword: une\tmisc_0: start_char=71|end_char=74\thead id: 5\thead: néphtopathie\tdeprel: det\n",
      "id: 5\tword: néphtopathie\tmisc_0: start_char=75|end_char=87\thead id: 3\thead: présente\tdeprel: obj\n",
      "id: 6\tword: de\tmisc_0: start_char=88|end_char=90\thead id: 7\thead: grade\tdeprel: case\n",
      "id: 7\tword: grade\tmisc_0: start_char=91|end_char=96\thead id: 5\thead: néphtopathie\tdeprel: nmod\n",
      "id: 8\tword: 1\tmisc_0: start_char=97|end_char=98\thead id: 7\thead: grade\tdeprel: nmod\n",
      "id: 9\tword: .\tmisc_0: start_char=99|end_char=100\thead id: 3\thead: présente\tdeprel: punct\n",
      "id: 1\tword: La\tmisc_0: start_char=101|end_char=103\thead id: 2\thead: patiente\tdeprel: det\n",
      "id: 2\tword: patiente\tmisc_0: start_char=104|end_char=112\thead id: 3\thead: présente\tdeprel: nsubj\n",
      "id: 3\tword: présente\tmisc_0: start_char=113|end_char=121\thead id: 0\thead: root\tdeprel: root\n",
      "id: 4\tword: aussi\tmisc_0: start_char=122|end_char=127\thead id: 3\thead: présente\tdeprel: advmod\n",
      "id: 5\tword: une\tmisc_0: start_char=128|end_char=131\thead id: 6\thead: néphtopathie\tdeprel: det\n",
      "id: 6\tword: néphtopathie\tmisc_0: start_char=132|end_char=144\thead id: 3\thead: présente\tdeprel: obj\n",
      "id: 7\tword: de\tmisc_0: start_char=145|end_char=147\thead id: 8\thead: grade\tdeprel: case\n",
      "id: 8\tword: grade\tmisc_0: start_char=148|end_char=153\thead id: 6\thead: néphtopathie\tdeprel: nmod\n",
      "id: 9\tword: 1\tmisc_0: start_char=154|end_char=155\thead id: 8\thead: grade\tdeprel: nmod\n",
      "id: 10\tword: .\tmisc_0: start_char=155|end_char=156\thead id: 3\thead: présente\tdeprel: punct\n",
      "id: 1\tword: La\tmisc_0: start_char=157|end_char=159\thead id: 2\thead: patiente\tdeprel: det\n",
      "id: 2\tword: patiente\tmisc_0: start_char=160|end_char=168\thead id: 3\thead: présente\tdeprel: nsubj\n",
      "id: 3\tword: présente\tmisc_0: start_char=169|end_char=177\thead id: 0\thead: root\tdeprel: root\n",
      "id: 4\tword: aussi\tmisc_0: start_char=178|end_char=183\thead id: 3\thead: présente\tdeprel: advmod\n",
      "id: 5\tword: une\tmisc_0: start_char=184|end_char=187\thead id: 6\thead: néphtopathie\tdeprel: det\n",
      "id: 6\tword: néphtopathie\tmisc_0: start_char=188|end_char=200\thead id: 3\thead: présente\tdeprel: obj\n",
      "id: 7\tword: de\tmisc_0: start_char=201|end_char=203\thead id: 8\thead: grade\tdeprel: case\n",
      "id: 8\tword: grade\tmisc_0: start_char=204|end_char=209\thead id: 6\thead: néphtopathie\tdeprel: nmod\n",
      "id: 9\tword: 1\tmisc_0: start_char=210|end_char=211\thead id: 8\thead: grade\tdeprel: nmod\n",
      "id: 10\tword: et\tmisc_0: start_char=212|end_char=214\thead id: 12\thead: a\tdeprel: cc\n",
      "id: 11\tword: elle\tmisc_0: start_char=215|end_char=219\thead id: 12\thead: a\tdeprel: nsubj\n",
      "id: 12\tword: a\tmisc_0: start_char=220|end_char=221\thead id: 3\thead: présente\tdeprel: conj\n",
      "id: 13\tword: de\tmisc_0: start_char=222|end_char=224\thead id: 15\thead: toux\tdeprel: det\n",
      "id: 14\tword: la\tmisc_0: start_char=225|end_char=227\thead id: 13\thead: de\tdeprel: fixed\n",
      "id: 15\tword: toux\tmisc_0: start_char=228|end_char=232\thead id: 12\thead: a\tdeprel: obj\n",
      "id: 16\tword: iatrogène\tmisc_0: start_char=233|end_char=242\thead id: 15\thead: toux\tdeprel: amod\n",
      "id: 17\tword: .\tmisc_0: start_char=242|end_char=243\thead id: 3\thead: présente\tdeprel: punct\n",
      "id: 1\tword: Elle\tmisc_0: start_char=244|end_char=248\thead id: 2\thead: voulait\tdeprel: nsubj\n",
      "id: 2\tword: voulait\tmisc_0: start_char=249|end_char=256\thead id: 0\thead: root\tdeprel: root\n",
      "id: 3\tword: acheter\tmisc_0: start_char=257|end_char=264\thead id: 2\thead: voulait\tdeprel: xcomp:obj\n",
      "id: 4\tword: et\tmisc_0: start_char=265|end_char=267\thead id: 5\thead: manger\tdeprel: cc\n",
      "id: 5\tword: manger\tmisc_0: start_char=268|end_char=274\thead id: 3\thead: acheter\tdeprel: conj\n",
      "id: 6\tword: une\tmisc_0: start_char=275|end_char=278\thead id: 7\thead: pomme\tdeprel: det\n",
      "id: 7\tword: pomme\tmisc_0: start_char=279|end_char=284\thead id: 3\thead: acheter\tdeprel: obj\n",
      "id: 8\tword: .\tmisc_0: start_char=284|end_char=285\thead id: 2\thead: voulait\tdeprel: punct\n",
      "id: 1\tword: Nous\tmisc_0: start_char=286|end_char=290\thead id: 3\thead: atteint\tdeprel: nsubj\n",
      "id: 2\tword: avons\tmisc_0: start_char=291|end_char=296\thead id: 3\thead: atteint\tdeprel: aux:tense\n",
      "id: 3\tword: atteint\tmisc_0: start_char=297|end_char=304\thead id: 0\thead: root\tdeprel: root\n",
      "id: 4\tword: la\tmisc_0: start_char=305|end_char=307\thead id: 5\thead: fin\tdeprel: det\n",
      "id: 5\tword: fin\tmisc_0: start_char=308|end_char=311\thead id: 3\thead: atteint\tdeprel: obj\n",
      "id: 6\tword: de\tmisc_0: None\thead id: 8\thead: sentier\tdeprel: case\n",
      "id: 7\tword: le\tmisc_0: None\thead id: 8\thead: sentier\tdeprel: det\n",
      "id: 8\tword: sentier\tmisc_0: start_char=315|end_char=322\thead id: 5\thead: fin\tdeprel: nmod\n",
      "id: 9\tword: .\tmisc_0: start_char=322|end_char=323\thead id: 3\thead: atteint\tdeprel: punct\n",
      "id: 1\tword: Syndrome\tmisc_0: start_char=324|end_char=332\thead id: 0\thead: root\tdeprel: root\n",
      "id: 2\tword: mains\tmisc_0: start_char=333|end_char=338\thead id: 1\thead: Syndrome\tdeprel: nmod\n",
      "id: 3\tword: pieds\tmisc_0: start_char=339|end_char=344\thead id: 1\thead: Syndrome\tdeprel: nmod\n",
      "id: 4\tword: de\tmisc_0: start_char=345|end_char=347\thead id: 5\thead: grade\tdeprel: case\n",
      "id: 5\tword: grade\tmisc_0: start_char=348|end_char=353\thead id: 3\thead: pieds\tdeprel: nmod\n",
      "id: 6\tword: 2\tmisc_0: start_char=354|end_char=355\thead id: 5\thead: grade\tdeprel: nmod\n",
      "id: 7\tword: .\tmisc_0: start_char=355|end_char=356\thead id: 1\thead: Syndrome\tdeprel: punct\n"
     ]
    }
   ],
   "source": [
    "print(*[f'id: {word.id}\\tword: {word.text}\\tmisc_0: {word.misc}\\thead id: {word.head}\\thead: {sent.words[word.head-1].text if word.head > 0 else \"root\"}\\tdeprel: {word.deprel}' for sent in doc3.sentences for word in sent.words], sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "16\n",
      "19\n",
      "25\n",
      "26\n",
      "28\n",
      "38\n",
      "41\n",
      "47\n",
      "48\n",
      "50\n",
      "53\n",
      "62\n",
      "71\n",
      "75\n",
      "88\n",
      "91\n",
      "97\n",
      "99\n",
      "101\n",
      "104\n",
      "113\n",
      "122\n",
      "128\n",
      "132\n",
      "145\n",
      "148\n",
      "154\n",
      "155\n",
      "157\n",
      "160\n",
      "169\n",
      "178\n",
      "184\n",
      "188\n",
      "201\n",
      "204\n",
      "210\n",
      "212\n",
      "215\n",
      "220\n",
      "222\n",
      "225\n",
      "228\n",
      "233\n",
      "242\n",
      "244\n",
      "249\n",
      "257\n",
      "265\n",
      "268\n",
      "275\n",
      "279\n",
      "284\n",
      "286\n",
      "291\n",
      "297\n",
      "305\n",
      "308\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-c78dca6da1c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'|'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "for sent in doc3.sentences :\n",
    "    for word in sent.words :\n",
    "        print(word.misc.split('|')[0].split(\"=\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\tword: Radioépithélite\tmisc_span_0: start_char=0|end_char=15\thead id: 0\thead: root\tdeprel: root\n",
      "id: 2\tword: de\tmisc_span_0: start_char=16|end_char=18\thead id: 3\thead: grade\tdeprel: case\n",
      "id: 3\tword: grade\tmisc_span_0: start_char=19|end_char=24\thead id: 1\thead: Radioépithélite\tdeprel: nmod\n",
      "id: 4\tword: 1\tmisc_span_0: start_char=25|end_char=26\thead id: 3\thead: grade\tdeprel: nmod\n",
      "id: 5\tword: .\tmisc_span_0: start_char=26|end_char=27\thead id: 1\thead: Radioépithélite\tdeprel: punct\n",
      "id: 1\tword: Asthésnie\tmisc_span_0: start_char=28|end_char=37\thead id: 0\thead: root\tdeprel: root\n",
      "id: 2\tword: de\tmisc_span_0: start_char=38|end_char=40\thead id: 3\thead: grade\tdeprel: case\n",
      "id: 3\tword: grade\tmisc_span_0: start_char=41|end_char=46\thead id: 1\thead: Asthésnie\tdeprel: nmod\n",
      "id: 4\tword: 3\tmisc_span_0: start_char=47|end_char=48\thead id: 3\thead: grade\tdeprel: nmod\n",
      "id: 5\tword: .\tmisc_span_0: start_char=48|end_char=49\thead id: 1\thead: Asthésnie\tdeprel: punct\n",
      "id: 1\tword: La\tmisc_span_0: start_char=50|end_char=52\thead id: 2\thead: patiente\tdeprel: det\n",
      "id: 2\tword: patiente\tmisc_span_0: start_char=53|end_char=61\thead id: 3\thead: présente\tdeprel: nsubj\n",
      "id: 3\tword: présente\tmisc_span_0: start_char=62|end_char=70\thead id: 0\thead: root\tdeprel: root\n",
      "id: 4\tword: une\tmisc_span_0: start_char=71|end_char=74\thead id: 5\thead: néphtopathie\tdeprel: det\n",
      "id: 5\tword: néphtopathie\tmisc_span_0: start_char=75|end_char=87\thead id: 3\thead: présente\tdeprel: obj\n",
      "id: 6\tword: de\tmisc_span_0: start_char=88|end_char=90\thead id: 7\thead: grade\tdeprel: case\n",
      "id: 7\tword: grade\tmisc_span_0: start_char=91|end_char=96\thead id: 5\thead: néphtopathie\tdeprel: nmod\n",
      "id: 8\tword: 1\tmisc_span_0: start_char=97|end_char=98\thead id: 7\thead: grade\tdeprel: nmod\n",
      "id: 9\tword: .\tmisc_span_0: start_char=99|end_char=100\thead id: 3\thead: présente\tdeprel: punct\n",
      "id: 1\tword: La\tmisc_span_0: start_char=101|end_char=103\thead id: 2\thead: patiente\tdeprel: det\n",
      "id: 2\tword: patiente\tmisc_span_0: start_char=104|end_char=112\thead id: 3\thead: présente\tdeprel: nsubj\n",
      "id: 3\tword: présente\tmisc_span_0: start_char=113|end_char=121\thead id: 0\thead: root\tdeprel: root\n",
      "id: 4\tword: aussi\tmisc_span_0: start_char=122|end_char=127\thead id: 3\thead: présente\tdeprel: advmod\n",
      "id: 5\tword: une\tmisc_span_0: start_char=128|end_char=131\thead id: 6\thead: néphtopathie\tdeprel: det\n",
      "id: 6\tword: néphtopathie\tmisc_span_0: start_char=132|end_char=144\thead id: 3\thead: présente\tdeprel: obj\n",
      "id: 7\tword: de\tmisc_span_0: start_char=145|end_char=147\thead id: 8\thead: grade\tdeprel: case\n",
      "id: 8\tword: grade\tmisc_span_0: start_char=148|end_char=153\thead id: 6\thead: néphtopathie\tdeprel: nmod\n",
      "id: 9\tword: 1\tmisc_span_0: start_char=154|end_char=155\thead id: 8\thead: grade\tdeprel: nmod\n",
      "id: 10\tword: .\tmisc_span_0: start_char=155|end_char=156\thead id: 3\thead: présente\tdeprel: punct\n",
      "id: 1\tword: La\tmisc_span_0: start_char=157|end_char=159\thead id: 2\thead: patiente\tdeprel: det\n",
      "id: 2\tword: patiente\tmisc_span_0: start_char=160|end_char=168\thead id: 3\thead: présente\tdeprel: nsubj\n",
      "id: 3\tword: présente\tmisc_span_0: start_char=169|end_char=177\thead id: 0\thead: root\tdeprel: root\n",
      "id: 4\tword: aussi\tmisc_span_0: start_char=178|end_char=183\thead id: 3\thead: présente\tdeprel: advmod\n",
      "id: 5\tword: une\tmisc_span_0: start_char=184|end_char=187\thead id: 6\thead: néphtopathie\tdeprel: det\n",
      "id: 6\tword: néphtopathie\tmisc_span_0: start_char=188|end_char=200\thead id: 3\thead: présente\tdeprel: obj\n",
      "id: 7\tword: de\tmisc_span_0: start_char=201|end_char=203\thead id: 8\thead: grade\tdeprel: case\n",
      "id: 8\tword: grade\tmisc_span_0: start_char=204|end_char=209\thead id: 6\thead: néphtopathie\tdeprel: nmod\n",
      "id: 9\tword: 1\tmisc_span_0: start_char=210|end_char=211\thead id: 8\thead: grade\tdeprel: nmod\n",
      "id: 10\tword: et\tmisc_span_0: start_char=212|end_char=214\thead id: 12\thead: a\tdeprel: cc\n",
      "id: 11\tword: elle\tmisc_span_0: start_char=215|end_char=219\thead id: 12\thead: a\tdeprel: nsubj\n",
      "id: 12\tword: a\tmisc_span_0: start_char=220|end_char=221\thead id: 3\thead: présente\tdeprel: conj\n",
      "id: 13\tword: de\tmisc_span_0: start_char=222|end_char=224\thead id: 15\thead: toux\tdeprel: det\n",
      "id: 14\tword: la\tmisc_span_0: start_char=225|end_char=227\thead id: 13\thead: de\tdeprel: fixed\n",
      "id: 15\tword: toux\tmisc_span_0: start_char=228|end_char=232\thead id: 12\thead: a\tdeprel: obj\n",
      "id: 16\tword: iatrogène\tmisc_span_0: start_char=233|end_char=242\thead id: 15\thead: toux\tdeprel: amod\n",
      "id: 17\tword: .\tmisc_span_0: start_char=242|end_char=243\thead id: 3\thead: présente\tdeprel: punct\n",
      "id: 1\tword: Elle\tmisc_span_0: start_char=244|end_char=248\thead id: 2\thead: voulait\tdeprel: nsubj\n",
      "id: 2\tword: voulait\tmisc_span_0: start_char=249|end_char=256\thead id: 0\thead: root\tdeprel: root\n",
      "id: 3\tword: acheter\tmisc_span_0: start_char=257|end_char=264\thead id: 2\thead: voulait\tdeprel: xcomp:obj\n",
      "id: 4\tword: et\tmisc_span_0: start_char=265|end_char=267\thead id: 5\thead: manger\tdeprel: cc\n",
      "id: 5\tword: manger\tmisc_span_0: start_char=268|end_char=274\thead id: 3\thead: acheter\tdeprel: conj\n",
      "id: 6\tword: une\tmisc_span_0: start_char=275|end_char=278\thead id: 7\thead: pomme\tdeprel: det\n",
      "id: 7\tword: pomme\tmisc_span_0: start_char=279|end_char=284\thead id: 3\thead: acheter\tdeprel: obj\n",
      "id: 8\tword: .\tmisc_span_0: start_char=284|end_char=285\thead id: 2\thead: voulait\tdeprel: punct\n",
      "id: 1\tword: Nous\tmisc_span_0: start_char=286|end_char=290\thead id: 3\thead: atteint\tdeprel: nsubj\n",
      "id: 2\tword: avons\tmisc_span_0: start_char=291|end_char=296\thead id: 3\thead: atteint\tdeprel: aux:tense\n",
      "id: 3\tword: atteint\tmisc_span_0: start_char=297|end_char=304\thead id: 0\thead: root\tdeprel: root\n",
      "id: 4\tword: la\tmisc_span_0: start_char=305|end_char=307\thead id: 5\thead: fin\tdeprel: det\n",
      "id: 5\tword: fin\tmisc_span_0: start_char=308|end_char=311\thead id: 3\thead: atteint\tdeprel: obj\n",
      "id: 6\tword: de\tmisc_span_0: None\thead id: 8\thead: sentier\tdeprel: case\n",
      "id: 7\tword: le\tmisc_span_0: None\thead id: 8\thead: sentier\tdeprel: det\n",
      "id: 8\tword: sentier\tmisc_span_0: start_char=315|end_char=322\thead id: 5\thead: fin\tdeprel: nmod\n",
      "id: 9\tword: .\tmisc_span_0: start_char=322|end_char=323\thead id: 3\thead: atteint\tdeprel: punct\n",
      "id: 1\tword: Syndrome\tmisc_span_0: start_char=324|end_char=332\thead id: 0\thead: root\tdeprel: root\n",
      "id: 2\tword: mains\tmisc_span_0: start_char=333|end_char=338\thead id: 1\thead: Syndrome\tdeprel: nmod\n",
      "id: 3\tword: pieds\tmisc_span_0: start_char=339|end_char=344\thead id: 1\thead: Syndrome\tdeprel: nmod\n",
      "id: 4\tword: de\tmisc_span_0: start_char=345|end_char=347\thead id: 5\thead: grade\tdeprel: case\n",
      "id: 5\tword: grade\tmisc_span_0: start_char=348|end_char=353\thead id: 3\thead: pieds\tdeprel: nmod\n",
      "id: 6\tword: 2\tmisc_span_0: start_char=354|end_char=355\thead id: 5\thead: grade\tdeprel: nmod\n",
      "id: 7\tword: .\tmisc_span_0: start_char=355|end_char=356\thead id: 1\thead: Syndrome\tdeprel: punct\n"
     ]
    }
   ],
   "source": [
    "print(*[f'id: {word.id}\\tword: {word.text}\\tmisc_span_0: {word.misc}\\thead id: {word.head}\\thead: {sent.words[word.head-1].text if word.head > 0 else \"root\"}\\tdeprel: {word.deprel}' for sent in doc3.sentences for word in sent.words], sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(doc3.entities)\n",
    "print(doc3.iter_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\tword: Syndrome\tmisc_span_0: start_char=0|end_char=8\thead id: 0\thead: root\tdeprel: root\n",
      "id: 2\tword: mains\tmisc_span_0: start_char=9|end_char=14\thead id: 1\thead: Syndrome\tdeprel: nmod\n",
      "id: 3\tword: pieds\tmisc_span_0: start_char=15|end_char=20\thead id: 1\thead: Syndrome\tdeprel: nmod\n",
      "id: 4\tword: de\tmisc_span_0: start_char=21|end_char=23\thead id: 5\thead: grade\tdeprel: case\n",
      "id: 5\tword: grade\tmisc_span_0: start_char=24|end_char=29\thead id: 3\thead: pieds\tdeprel: nmod\n",
      "id: 6\tword: 2\tmisc_span_0: start_char=30|end_char=31\thead id: 5\thead: grade\tdeprel: nmod\n",
      "id: 7\tword: .\tmisc_span_0: start_char=31|end_char=32\thead id: 1\thead: Syndrome\tdeprel: punct\n"
     ]
    }
   ],
   "source": [
    "list_doc=[]\n",
    "for sent in doc3.sentences :\n",
    "    list_doc.append(sent.text)\n",
    "\n",
    "list_docobj=[]\n",
    "for doc in list_doc:    \n",
    "    list_docobj.append(nlp_fr(doc))\n",
    "    \n",
    "\n",
    "doc4=list_docobj[-1]\n",
    "print(*[f'id: {word.id}\\tword: {word.text}\\tmisc_span_0: {word.misc}\\thead id: {word.head}\\thead: {sent.words[word.head-1].text if word.head > 0 else \"root\"}\\tdeprel: {word.deprel}' for sent in doc4.sentences for word in sent.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Radioépithélite de grade 1.\n",
      "Asthésnie de grade 3.\n",
      "La patiente présente une néphtopathie de grade 1.\n",
      "La patiente présente aussi une néphtopathie de grade 1.\n",
      "La patiente présente aussi une néphtopathie de grade 1 et elle a de la toux iatrogène.\n",
      "Elle voulait acheter et manger une pomme.\n",
      "Nous avons atteint la fin de le sentier.\n",
      "Syndrome mains pieds de grade 2.\n"
     ]
    }
   ],
   "source": [
    "for doc_text in list_docobj :\n",
    "    for sent in doc_text.sentences :\n",
    "        new_sent = sent.words[0].text\n",
    "        for word in sent.words[1:] :\n",
    "            if word.text != \".\":\n",
    "                new_sent = new_sent + \" \" + word.text\n",
    "            else :\n",
    "                new_sent = new_sent + word.text\n",
    "    print(new_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Sentence 1 tokens =======\n",
      "id: (1,)\ttext: Syndrome\n",
      "id: (2,)\ttext: mains\n",
      "id: (3,)\ttext: pieds\n",
      "id: (4,)\ttext: de\n",
      "id: (5,)\ttext: grade\n",
      "id: (6,)\ttext: 2\n",
      "id: (7,)\ttext: .\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(doc4.sentences):\n",
    "    print(f'====== Sentence {i+1} tokens =======')\n",
    "    print(*[f'id: {token.id}\\ttext: {token.text}' for token in sentence.tokens], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Syndrome mains pieds de grade 2.']\n"
     ]
    }
   ],
   "source": [
    "print([sentence.text for sentence in doc4.sentences])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To BRAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "dict_id={}\n",
    "list_entities=[]\n",
    "dict_relations={}\n",
    "brat_dir = cfg[\"brat_dirs\"][\"stanza\"]\n",
    "\n",
    "### 1 : Remplissage des .txt\n",
    "# for doc_text in list_docobj :\n",
    "#     i += 1\n",
    "#     with open(\"/rapids/my_data/brat/data/stanza_annots/sent_\" + str(i) + \".txt\", 'w') as f :\n",
    "#         f.write(doc_text.text)\n",
    "## le problème avec le code ci-dessus, c'est quand il y a des \"du\" = \"de\" + \"le\". On remplace par le code ci-dessous, mais il y a certainment une autre manière de faire avec les processors, à inverstiguer\n",
    "for doc_text in list_docobj :\n",
    "    i += 1\n",
    "    for sent in doc_text.sentences :\n",
    "        new_sent = sent.words[0].text\n",
    "        for word in sent.words[1:] :\n",
    "            if word.text != \".\":\n",
    "                new_sent = new_sent + \" \" + word.text\n",
    "            else :\n",
    "                new_sent = new_sent + word.text\n",
    "    with open(brat_dir + \"/sent_\" + str(i) + \".txt\", 'w') as f :\n",
    "        f.write(new_sent)\n",
    "i=0\n",
    "### 2 : Remplissage des .ann\n",
    "for doc in list_docobj :\n",
    "    i += 1\n",
    "    with open(brat_dir + \"/sent_\" + str(i) + \".ann\", 'w') as f_ann :\n",
    "        # 1ere boucle entity\n",
    "        instance_brat = 0\n",
    "        for sent in doc.sentences :\n",
    "            for word in sent.words :\n",
    "                if word.misc is not None :\n",
    "                    span0,span1= str(word.misc).split('|')[0].split(\"=\")[-1], str(word.misc).split('|')[1].split(\"=\")[-1]\n",
    "                    bratline1 = 'T' + str(instance_brat) + '\t' + word.upos  + ' ' + str(span0) \\\n",
    "                               + ' ' + str(span1) + '\t' + word.text + '\\n'\n",
    "                    dict_id[word.id]='T' + str(instance_brat)\n",
    "                    instance_brat += 1\n",
    "                    f_ann.write(bratline1)\n",
    "                    \n",
    "                # pour remplissage du annot.conf\n",
    "                # entities\n",
    "                if str(word.upos) not in list_entities :\n",
    "                    list_entities.append(str(word.upos))\n",
    "            # 2eme boucle relations\n",
    "            relation_brat = 0\n",
    "            for word in sent.words :\n",
    "                if word.head > 0 :\n",
    "                    bratline_rel = 'R' + str(relation_brat) + '\t' + word.deprel + ' Arg1:'+ dict_id[word.head] + ' Arg2:' + dict_id[word.id] + '\t' + '\\n'\n",
    "                    f_ann.write(bratline_rel)\n",
    "                    relation_brat += 1\n",
    "                    # pour remplissage du annot.conf\n",
    "                    #relations\n",
    "                    if str(word.deprel).replace(\":\",\"_\") not in dict_relations :\n",
    "                        dict_relations[str(word.deprel).replace(\":\",\"_\")] = [[word.upos, sent.words[word.head].upos]]\n",
    "                    elif [word.upos, sent.words[word.head].upos] not in dict_relations[str(word.deprel).replace(\":\",\"_\")] :\n",
    "                        dict_relations[str(word.deprel).replace(\":\",\"_\")].append([word.upos, sent.words[word.head].upos])\n",
    "### 3 : Remplissage du annot.conf :\n",
    "with open(brat_dir + \"/annotation.conf\", 'w') as f :\n",
    "    f.write(\"# -*- Mode: Text; tab-width: 8; indent-tabs-mode: nil; coding: utf-8; -*-\\n\")\n",
    "    f.write(\"# vim:set ft=conf ts=2 sw=2 sts=2 autoindent:\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"# Simple text-based definitions of entity, relation and event types\\n\")\n",
    "    f.write(\"# and event attributes for the BioNLP Shared Task 2011 EPI task.\\n\")\n",
    "    f.write(\"\\n\\n\")\n",
    "    f.write(\"[entities]\\n\\n\")\n",
    "    for entity in list_entities :\n",
    "        f.write(entity + \"\\n\")\n",
    "    f.write(\"\\n\"+\"[relations]\" + \"\\n\\n\")\n",
    "    for relation in dict_relations :\n",
    "        for el in dict_relations[relation] :\n",
    "            line = relation + '\t' + 'Arg1:'+ el[0] + ', ' + 'Arg2:'+ el[1] + \"\\n\"\n",
    "            f.write(line)\n",
    "    f.write(\"\\n\\n\")\n",
    "    f.write(\"[events]\\n\\n\")\n",
    "    f.write(\"[attributes]\")                   "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# R3\tEmployment Arg1:T8 Arg2:T9\t\n",
    "# R1\tLocated Arg1:T1 Arg2:T2\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in doc3.sentences :\n",
    "    #print(sent.words[0].head)\n",
    "    for word in sent.words :\n",
    "        print(sent.words[word.head].upos)\n",
    "  #print(word.misc.split('|')[1].split(\"=\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = {\n",
    "# \t'processors': 'tokenize,mwt,pos', # Comma-separated list of processors to use\n",
    "# \t'lang': 'fr', # Language code for the language to build the Pipeline in\n",
    "# \t'tokenize_model_path': './fr_gsd_models/fr_gsd_tokenizer.pt', # Processor-specific arguments are set with keys \"{processor_name}_{argument_name}\"\n",
    "# \t'mwt_model_path': './fr_gsd_models/fr_gsd_mwt_expander.pt',\n",
    "# \t'pos_model_path': './fr_gsd_models/fr_gsd_tagger.pt',\n",
    "# \t'pos_pretrain_path': './fr_gsd_models/fr_gsd.pretrain.pt',\n",
    "# \t'tokenize_pretokenized': True # Use pretokenized text as input and disable tokenization\n",
    "# }\n",
    "# nlp = stanza.Pipeline(**config) # Initialize the pipeline using a configuration dict\n",
    "# doc = nlp(\"Van Gogh grandit au sein d'une famille de l'ancienne bourgeoisie .\") # Run the pipeline on the pretokenized input text\n",
    "# print(doc) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
